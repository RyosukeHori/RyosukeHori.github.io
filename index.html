<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ryosuke Hori </title> <meta name="author" content="Ryosuke Hori"> <meta name="description" content="I am a PhD student at [Keio University](https://www.keio.ac.jp/en/), working under the supervision of Prof. [Hideo Saito](https://www.st.keio.ac.jp/en/tprofile/ics/hideo.saito.html) since September 2022. I am also a research assistant at the [Digital Human Research Team](https://dhrt.notion.site/Digital-Human-Research-Team-AIRC-AIST-8d53e3c09734402092effc93f52eee6a), part of the [Artificial Intelligence Research Center](https://www.airc.aist.go.jp/en/) at the [National Institute of Advanced Industrial Science and Technology (AIST)](https://www.aist.go.jp/index_en.html), where I work under Dr. Mitsunori Tada. Currently, I am a visiting researcher at the [Kris Kitani](https://kriskitani.github.io/) Lab in the Robotics Institute (RI) at [Carnegie Mellon University](https://www.cmu.edu/). I am also a Research Fellow of the JSPS Research Fellowships for Young Scientists (DC1)."> <meta name="keywords" content="ryosuke, hori, ryosukehori"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg?73b1ca37615ecff9a9209a15a935bc83"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ryosukehori.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ryosuke Hori</span> </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?73b1ca37615ecff9a9209a15a935bc83" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hi, I am Ryosuke Hori (堀 涼介).</p> <p>I am a PhD student at <a href="https://www.keio.ac.jp/en/" rel="external nofollow noopener" target="_blank">Keio University</a>, working under the supervision of Prof. <a href="https://www.st.keio.ac.jp/en/tprofile/ics/hideo.saito.html" rel="external nofollow noopener" target="_blank">Hideo Saito</a> since September 2022. I am also a research assistant at the <a href="https://dhrt.notion.site/Digital-Human-Research-Team-AIRC-AIST-8d53e3c09734402092effc93f52eee6a" rel="external nofollow noopener" target="_blank">Digital Human Research Team</a>, part of the <a href="https://www.airc.aist.go.jp/en/" rel="external nofollow noopener" target="_blank">Artificial Intelligence Research Center</a> at the <a href="https://www.aist.go.jp/index_en.html" rel="external nofollow noopener" target="_blank">National Institute of Advanced Industrial Science and Technology (AIST)</a>, where I work under Dr. Mitsunori Tada. Currently, I am a visiting researcher at the <a href="https://kriskitani.github.io/" rel="external nofollow noopener" target="_blank">Kris Kitani</a> Lab in the Robotics Institute (RI) at <a href="https://www.cmu.edu/" rel="external nofollow noopener" target="_blank">Carnegie Mellon University</a>. I am also a Research Fellow of the JSPS Research Fellowships for Young Scientists (DC1).</p> <p><a href="mailto:hori-rysk@keio.jp">Email</a> / <a href="https://ryosukehori.github.io/cv/">CV</a> / <a href="https://scholar.google.co.in/citations?user=VMIR3zwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a> / <a href="https://github.com/RyosukeHori" rel="external nofollow noopener" target="_blank">Github</a> / <a href="">Linkedin</a></p> </div> <h2> <a href="/news/" style="color: inherit"><strong>News</strong></a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Mar 11, 2025</th> <td> Gave a TVCG invited presentation at <a href="https://ieeevr.org/2025/" rel="external nofollow noopener" target="_blank">IEEE VR</a> 2025. <img class="emoji" title=":microphone:" alt=":microphone:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3a4.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 21, 2024</th> <td> Gave an invited talk at <a href="https://sites.google.com/keio.jp/ismar2024-iw-p3hse/" rel="external nofollow noopener" target="_blank">IW-P3HSE</a> Workshop, IEEE ISMAR. <img class="emoji" title=":microphone:" alt=":microphone:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f3a4.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 15, 2024</th> <td> One paper accepted to <a href="https://www.computer.org/csdl/journal/tg" rel="external nofollow noopener" target="_blank">IEEE Transactions on Visualization and Computer Graphics (TVCG)</a>. <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2024</th> <td> Started a visiting researcher position at <a href="https://www.cmu.edu/" rel="external nofollow noopener" target="_blank">Carnegie Mellon University</a>. <img class="emoji" title=":us:" alt=":us:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1fa-1f1f8.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 13, 2023</th> <td> Received the “Academic Encouragement Award” at VRSJ 2023. <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 28, 2023</th> <td> Received the “Demo Presentation Award” and the “Student Encouragement Award” at MIRU 2023. <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 01, 2023</th> <td> Selected as a recipient of the <a href="https://www.jsps.go.jp/english/e-pd/" rel="external nofollow noopener" target="_blank">JSPS Research Fellowship for Young Scientists</a> (DC1, Acceptance Rate 17.3%). <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 19, 2023</th> <td> Presented a poster at <a href="https://visapp.scitevents.org/?y=2023" rel="external nofollow noopener" target="_blank">VISAPP</a>’23 in Lisbon. <img class="emoji" title=":portugal:" alt=":portugal:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1f5-1f1f9.png" height="20" width="20"> </td> </tr> </table> </div> </div> <hr> <h2> <a href="/publications/" style="color: inherit"><strong>Publications</strong></a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="">Conference</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CVPRW2025-480.webp 480w,/assets/img/publication_preview/CVPRW2025-800.webp 800w,/assets/img/publication_preview/CVPRW2025-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/CVPRW2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CVPRW2025.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="CHIW2024" class="col-sm-8"> <div class="title">Human Mesh Reconstruction of Sports Players with Multiple Dynamic Cameras</div> <div class="author"> Yamato Hokari, <em>Ryosuke Hori</em>, and Hideo Saito </div> <div class="periodical"> <em>IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) Workshop</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="">Conference</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CHIW2025-480.webp 480w,/assets/img/publication_preview/CHIW2025-800.webp 800w,/assets/img/publication_preview/CHIW2025-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/CHIW2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CHIW2025.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="CHIW2025" class="col-sm-8"> <div class="title">Realtime Smart Gait Poser for foot augmentation</div> <div class="author"> Hiroyuki Deguchi, <em>Ryosuke Hori</em>, Tsubasa Maruyama, Mitsunori Tada, and Hideo Saito </div> <div class="periodical"> <em>ACM Conference on Human Factors in Computing Systems (CHI) Workshop</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Journal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/TVCG2024.gif" sizes="200px"> <img src="/assets/img/publication_preview/TVCG2024.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TVCG2024.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="TVCG2024" class="col-sm-8"> <div class="title">EventPointMesh: Human Mesh Recovery Solely From Event Point Clouds</div> <div class="author"> <em>Ryosuke Hori</em>, Mariko Isogawa, Dan Mikami, and Hideo Saito </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics (TVCG) / IEEE Conference on Virtual Reality and 3D User Interfaces (VR)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TVCG.2024.3462816" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ryosukehori.github.io/EPM_ProjectPage/" class="btn btn-sm z-depth-0" role="button">project</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="">Conference</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Yamane2024-480.webp 480w,/assets/img/publication_preview/Yamane2024-800.webp 800w,/assets/img/publication_preview/Yamane2024-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/Yamane2024.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Yamane2024.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Yamane2024" class="col-sm-8"> <div class="title">Occlusion Free Multi-Object Tracking Extention using Multi-Camera for Sport</div> <div class="author"> Momoe Yamane, Akimasa Kondo, Masashi Hatano, <em>Ryosuke Hori</em>, and Hideo Saito </div> <div class="periodical"> <em>Proceedings of the 7th ACM International Workshop on Multimedia Content Analysis in Sports (MMSports)</em>, Melbourne VIC, Australia, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3689061.3689070" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>As data analysis becomes increasingly significant, streamlining data collection is essential, particularly in sports. Among various aspects, player performance analysis is crucial for both professional and amateur levels. In computer vision, Multi-Object Tracking (MOT) and Multi-Camera Multi-Object Tracking (MCMOT) enable the analysis of people’s trajectories captured in videos. However, many existing methods do not account for crowded scenarios, such as sports matches, and require complex preprocessing of datasets, making them impractical for real-world applications. To address these challenges, we introduce a simple yet novel extension of MOT methods by utilizing the Gaussian distribution to associate tracking information obtained from multiple cameras. By integrating tracking data from all cameras, our methodology effectively mitigates identity switches and expands the tracking range. Experimental results demonstrate our tracking system’s effectiveness, showing a reduction in ID switches and false negatives compared to results achieved with a standard multi-object tracker.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2024_Deguchi-480.webp 480w,/assets/img/publication_preview/MIRU2024_Deguchi-800.webp 800w,/assets/img/publication_preview/MIRU2024_Deguchi-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2024_Deguchi.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2024_Deguchi.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2024_Deguchi" class="col-sm-8"> <div class="title">Realtime Smart Gait Poser: Real-time Estimation of Walking Posture Using Smart Shoes (in Japanese)</div> <div class="author"> Hiroyuki Deguchi, <em>Ryosuke Hori</em>, Mitsunori Tada, and Hideo Saito </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2024_Yazaki-480.webp 480w,/assets/img/publication_preview/MIRU2024_Yazaki-800.webp 800w,/assets/img/publication_preview/MIRU2024_Yazaki-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2024_Yazaki.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2024_Yazaki.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2024_Yazaki" class="col-sm-8"> <div class="title">Estimation of First-Person View Videos from a Second-Person Perspective Camera Utilizing Pre-scanned 3D Environments (in Japanese)</div> <div class="author"> Hiroki Yazaki, <em>Ryosuke Hori</em>, Tomoya Matsubara, and Hideo Saito </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2024_Numata-480.webp 480w,/assets/img/publication_preview/MIRU2024_Numata-800.webp 800w,/assets/img/publication_preview/MIRU2024_Numata-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2024_Numata.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2024_Numata.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2023_Numata" class="col-sm-8"> <div class="title">3D Human Pose Estimation Using Wearable Insole-type Pressure Sensors (in Japanese)</div> <div class="author"> Ryotaro Numata, <em>Ryosuke Hori</em>, Fukuhara Yoshihiro, and Mariko Isogawa </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Journal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/NokiharaJournal2023-480.webp 480w,/assets/img/publication_preview/NokiharaJournal2023-800.webp 800w,/assets/img/publication_preview/NokiharaJournal2023-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/NokiharaJournal2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NokiharaJournal2023.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="NokiharaJournal2023" class="col-sm-8"> <div class="title">Future Prediction of Shuttlecock Trajectory in Badminton Using Player’s Information</div> <div class="author"> Yuka Nokihara, Ryo Hachiuma, <em>Ryosuke Hori</em>, and Hideo Saito </div> <div class="periodical"> <em>Journal of Imaging</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3390/jimaging9050099" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Video analysis has become an essential aspect of net sports, such as badminton. Accurately predicting the future trajectory of balls and shuttlecocks can significantly benefit players by enhancing their performance and enabling them to devise effective game strategies. This paper aims to analyze data to provide players with an advantage in the fast-paced rallies of badminton matches. The paper delves into the innovative task of predicting future shuttlecock trajectories in badminton match videos and presents a method that takes into account both the shuttlecock position and the positions and postures of the players. In the experiments, players were extracted from the match video, their postures were analyzed, and a time-series model was trained. The results indicate that the proposed method improved accuracy by 13% compared to methods that solely used shuttlecock position information as input, and by 8.4% compared to methods that employed both shuttlecock and player position information as input.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="">Conference</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/NokiharaConference2023-480.webp 480w,/assets/img/publication_preview/NokiharaConference2023-800.webp 800w,/assets/img/publication_preview/NokiharaConference2023-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/NokiharaConference2023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NokiharaConference2023.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="NokiharaConference2023" class="col-sm-8"> <div class="title">Prediction of Shuttle Trajectory in Badminton Using Player’s Position.</div> <div class="author"> Yuka Nokihara, <em>Ryosuke Hori</em>, Ryo Hachiuma, and Hideo Saito </div> <div class="periodical"> <em>International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISIGRAPP)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2023_Hori-480.webp 480w,/assets/img/publication_preview/MIRU2023_Hori-800.webp 800w,/assets/img/publication_preview/MIRU2023_Hori-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2023_Hori.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2023_Hori.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2023_Hori" class="col-sm-8"> <div class="title">3D Human Pose and Shape Estimation Using an Event Camera (in Japanese)</div> <div class="author"> <em>Ryosuke Hori</em>, Mariko Isogawa, Dan Mikami, and Hideo Saito </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>MIRU Student Encouragement Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/VRSJ2023-480.webp 480w,/assets/img/publication_preview/VRSJ2023-800.webp 800w,/assets/img/publication_preview/VRSJ2023-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/VRSJ2023.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="VRSJ2023.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="VRSJ2023_Hori" class="col-sm-8"> <div class="title">3D Human Pose and Shape Estimation Using an Event Camera (in Japanese)</div> <div class="author"> <em>Ryosuke Hori</em>, Mariko Isogawa, Dan Mikami, and Hideo Saito </div> <div class="periodical"> <em>Annual Conference of the Virtual Reality Society of Japan (VRSJ)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>VRSJ Academic Encouragement Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2023_Deguchi-480.webp 480w,/assets/img/publication_preview/MIRU2023_Deguchi-800.webp 800w,/assets/img/publication_preview/MIRU2023_Deguchi-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2023_Deguchi.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2023_Deguchi.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2023_Deguchi" class="col-sm-8"> <div class="title">Event Point Mesh in Realtime: Real-Time 3D Human Pose and Shape Estimation from Event Data (in Japanese)</div> <div class="author"> Hiroyuki Deguchi, Ikeda Wataru, <em>Ryosuke Hori</em>, Mariko Isogawa, and Hideo Saito </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>MIRU Demo Presentation Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Journal</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Access2022-480.webp 480w,/assets/img/publication_preview/Access2022-800.webp 800w,/assets/img/publication_preview/Access2022-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/Access2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Access2022.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="IEEEAccess2022" class="col-sm-8"> <div class="title">Silhouette-Based 3D Human Pose Estimation Using a Single Wrist-Mounted 360° Camera</div> <div class="author"> <em>Ryosuke Hori</em>, Ryo Hachiuma, Mariko Isogawa, Dan Mikami, and Hideo Saito </div> <div class="periodical"> <em>IEEE Access</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ACCESS.2022.3177623" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://www.hvrl.ics.keio.ac.jp/hori/ieee-access/sil-hpe/index.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">project</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2023_Hori-480.webp 480w,/assets/img/publication_preview/MIRU2023_Hori-800.webp 800w,/assets/img/publication_preview/MIRU2023_Hori-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2023_Hori.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2023_Hori.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="CVIM2022" class="col-sm-8"> <div class="title">3D Human Pose and Shape Estimation Using an Event Camera (in Japanese)</div> <div class="author"> <em>Ryosuke Hori</em>, Mariko Isogawa, Dan Mikami, and Hideo Saito </div> <div class="periodical"> <em>IPSJ SIG-CVIM Conference</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Honorable Mention Award from IPSJ SIG-CVIM, Excellent Research Presentation Award from IPSJ SIG-CGVI, Student Presentation Award from IPSJ SIG-CGVI</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CCC2022-480.webp 480w,/assets/img/publication_preview/CCC2022-800.webp 800w,/assets/img/publication_preview/CCC2022-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/CCC2022.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CCC2022.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="CCC2022" class="col-sm-8"> <div class="title">Foot Pressure-Aware Human Mesh Recovery in 3D Scenes (in Japanese)</div> <div class="author"> <em>Ryosuke Hori</em>, and Ryotaro Numata </div> <div class="periodical"> <em>cvpaper.challenge Conference Summer (CCC)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Awarded</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Best Paper Honorable Mention Award</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="">Conference</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ICIP2021-480.webp 480w,/assets/img/publication_preview/ICIP2021-800.webp 800w,/assets/img/publication_preview/ICIP2021-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/ICIP2021.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ICIP2021.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ICIP2021" class="col-sm-8"> <div class="title">Silhouette-Based Synthetic Data Generation For 3D Human Pose Estimation With A Single Wrist-Mounted 360° Camera</div> <div class="author"> <em>Ryosuke Hori</em>, Ryo Hachiuma, Hideo Saito, Mariko Isogawa, and Dan Mikami </div> <div class="periodical"> <em>2021 IEEE International Conference on Image Processing (ICIP)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ICIP42928.2021.9506043" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#9f3600"> <a href="">Domestic Conf.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MIRU2021-480.webp 480w,/assets/img/publication_preview/MIRU2021-800.webp 800w,/assets/img/publication_preview/MIRU2021-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/assets/img/publication_preview/MIRU2021.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MIRU2021.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MIRU2021" class="col-sm-8"> <div class="title">Silhouette-Based Synthetic Data Generation For 3D Human Pose Estimation With A Single Wrist-Mounted 360° Camera (in Japanese)</div> <div class="author"> <em>Ryosuke Hori</em>, Ryo Hachiuma, Hideo Saito, Mariko Isogawa, and Dan Mikami </div> <div class="periodical"> <em>Meeting on Image Recognition and Understanding (MIRU)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ryosuke Hori. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>